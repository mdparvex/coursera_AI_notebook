{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hrXv0rU9sIma"
   },
   "source": [
    "# Custom Training Basics\n",
    "\n",
    "In this ungraded lab you'll gain a basic understanding of building custom training loops. \n",
    "- It takes you through the underlying logic of fitting any model to a set of inputs and outputs. \n",
    "- You will be training your model on the linear equation for a straight line, wx + b. \n",
    "- You will implement basic linear regression from scratch using gradient tape.\n",
    "- You will try to minimize the loss incurred by the model using linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LXMVuV0VhDr"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NiolgWMPgpwI"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K7O6eEGF5DcN"
   },
   "source": [
    "## Define Model\n",
    "\n",
    "You define your model as a class. \n",
    "- `x` is your input tensor. \n",
    "- The model should output values of **wx+b**. \n",
    "- You'll start off by initializing w and b to random values. \n",
    "- During the training process, values of w and b get updated in accordance with linear regression so as to minimize the loss incurred by the model. \n",
    "- Once you arrive at optimal values for w and b, the model would have been trained to correctly predict the values of wx+b.\n",
    "\n",
    "Hence, \n",
    "- **w** and **b** are trainable weights of the model. \n",
    "- **x** is the input\n",
    "- **y** = wx + b is the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WRu7Pze7wk8"
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "  def __init__(self):\n",
    "    # Initialize the weights to `2.0` and the bias to `1.0`\n",
    "    # In practice, these should be initialized to random values (for example, with `tf.random.normal`)\n",
    "    self.w = tf.Variable(2.0)\n",
    "    self.b = tf.Variable(1.0)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    return self.w * x + self.b\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xa6j_yXa-j79"
   },
   "source": [
    "### Define a loss function\n",
    "\n",
    "A loss function measures how well the output of a model for a given input matches the target output. \n",
    "- The goal is to minimize this difference during training. \n",
    "- Let's use the standard L2 loss, also known as the least square errors\n",
    "$$Loss = \\sum_{i} \\left (y_{pred}^i - y_{target}^i \\right )^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0ysUFGY924U"
   },
   "outputs": [],
   "source": [
    "def loss(predicted_y, target_y):\n",
    "  return tf.reduce_mean(tf.square(predicted_y - target_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qutT_fkl_CBc"
   },
   "source": [
    "### Obtain training data\n",
    "\n",
    "First, synthesize the training data using the \"true\" w and \"true\" b. \n",
    "\n",
    "$$y = w_{true} \\times x + b_{true} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxPTb-kt_N5m"
   },
   "outputs": [],
   "source": [
    "TRUE_w = 3.0\n",
    "TRUE_b = 2.0\n",
    "NUM_EXAMPLES = 1000\n",
    "\n",
    "xs  = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "\n",
    "ys = (TRUE_w * xs) + TRUE_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-50nq-wPBsAW"
   },
   "source": [
    "Before training the model, visualize the loss value by plotting the model's predictions in red crosses and the training data in blue dots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eb83LtrB4nt"
   },
   "outputs": [],
   "source": [
    "def plot_data(inputs, outputs, predicted_outputs):\n",
    "  real = plt.scatter(inputs, outputs, c='b', marker='.')\n",
    "  predicted = plt.scatter(inputs, predicted_outputs, c='r', marker='+')\n",
    "  plt.legend((real,predicted), ('Real Data', 'Predicted Data'))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XL25a_aEOuim"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 1.822367\n"
     ]
    }
   ],
   "source": [
    "plot_data(xs, ys, model(xs))\n",
    "print('Current loss: %1.6f' % loss(model(xs), ys).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSDP-yeq_4jE"
   },
   "source": [
    "### Define a training loop\n",
    "\n",
    "With the network and training data, train the model using [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) \n",
    "- Gradient descent updates the trainable weights **w** and **b** to reduce the loss. \n",
    "\n",
    "\n",
    "There are many variants of the gradient descent scheme that are captured in `tf.train.Optimizer`—our recommended implementation. In the spirit of building from first principles, here you will implement the basic math yourself.\n",
    "- You'll use `tf.GradientTape` for automatic differentiation\n",
    "- Use `tf.assign_sub` for decrementing a value.  Note that assign_sub combines `tf.assign` and `tf.sub`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBIACgdnA55X"
   },
   "outputs": [],
   "source": [
    "def train(model, inputs, outputs, learning_rate):\n",
    "  with tf.GradientTape() as t:\n",
    "    current_loss = loss(model(inputs), outputs)\n",
    "  dw, db = t.gradient(current_loss, [model.w, model.b])\n",
    "  model.w.assign_sub(learning_rate * dw)\n",
    "  model.b.assign_sub(learning_rate * db)\n",
    "\n",
    "  return current_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwWPaJryD2aN"
   },
   "source": [
    "Finally, you can iteratively run through the training data and see how `w` and `b` evolve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdfkR223D9dW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0: w=2.00 b=1.00, loss=1.82237\n",
      "Epoch  1: w=2.17 b=1.19, loss=1.21747\n",
      "Epoch  2: w=2.32 b=1.35, loss=0.81380\n",
      "Epoch  3: w=2.43 b=1.47, loss=0.54425\n",
      "Epoch  4: w=2.53 b=1.57, loss=0.36416\n",
      "Epoch  5: w=2.61 b=1.65, loss=0.24378\n",
      "Epoch  6: w=2.68 b=1.72, loss=0.16327\n",
      "Epoch  7: w=2.74 b=1.77, loss=0.10940\n",
      "Epoch  8: w=2.78 b=1.82, loss=0.07333\n",
      "Epoch  9: w=2.82 b=1.85, loss=0.04917\n",
      "Epoch 10: w=2.85 b=1.88, loss=0.03299\n",
      "Epoch 11: w=2.88 b=1.90, loss=0.02214\n",
      "Epoch 12: w=2.90 b=1.92, loss=0.01486\n",
      "Epoch 13: w=2.92 b=1.94, loss=0.00998\n",
      "Epoch 14: w=2.93 b=1.95, loss=0.00670\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "# Collect the history of W-values and b-values to plot later\n",
    "list_w, list_b = [], []\n",
    "epochs = range(15)\n",
    "losses = []\n",
    "for epoch in epochs:\n",
    "  list_w.append(model.w.numpy())\n",
    "  list_b.append(model.b.numpy())\n",
    "  current_loss = train(model, xs, ys, learning_rate=0.1)\n",
    "  losses.append(current_loss)\n",
    "  print('Epoch %2d: w=%1.2f b=%1.2f, loss=%2.5f' %\n",
    "        (epoch, list_w[-1], list_b[-1], current_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EI_1PwOBR6TW"
   },
   "source": [
    "In addition to the values for losses, you also plot the progression of trainable variables over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q8gJThOCNXAp"
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, list_w, 'r',\n",
    "       epochs, list_b, 'b')\n",
    "plt.plot([TRUE_w] * len(epochs), 'r--',\n",
    "      [TRUE_b] * len(epochs), 'b--')\n",
    "plt.legend(['w', 'b', 'True w', 'True b'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QsTbG9J2MM9W"
   },
   "source": [
    "## Plots for Evaluation\n",
    "Now you can plot the actual outputs in red and the model's predictions in blue on a set of random test examples.\n",
    "\n",
    "You can see that the model is able to make predictions on the test set fairly accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRHpHCJ3273d"
   },
   "outputs": [],
   "source": [
    "test_inputs  = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "test_outputs = test_inputs * TRUE_w + TRUE_b\n",
    "\n",
    "predicted_test_outputs = model(test_inputs)\n",
    "plot_data(test_inputs, test_outputs, predicted_test_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zY-j2FJYSfis"
   },
   "source": [
    "Visualize the cost function against the values of each of the trainable weights the model approximated to over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hY-gQWFfOIu-"
   },
   "outputs": [],
   "source": [
    "def plot_loss_for_weights(weights_list, losses):\n",
    "  for idx, weights in enumerate(weights_list):\n",
    "    plt.subplot(120 + idx + 1)\n",
    "    plt.plot(weights['values'], losses, 'r')\n",
    "    plt.plot(weights['values'], losses, 'bo')\n",
    "    plt.xlabel(weights['name'])\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    \n",
    "weights_list = [{ 'name' : \"w\",\n",
    "                  'values' : list_w\n",
    "                },\n",
    "                {\n",
    "                  'name' : \"b\",\n",
    "                  'values' : list_b\n",
    "                }]\n",
    "\n",
    "plot_loss_for_weights(weights_list, losses)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Training Basics.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
